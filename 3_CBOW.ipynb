{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_jbFcxFZhG5K",
        "outputId": "531e8b86-6c03-4552-e670-c721c2e42ea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting keras-nlp\n",
            "  Downloading keras_nlp-0.6.3-py3-none-any.whl (584 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.5/584.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim==4.2.0\n",
            "  Downloading gensim-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (6.4.0)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Collecting keras-core (from keras-nlp)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (23.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (2023.6.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (13.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.8)\n",
            "Collecting tensorflow-text (from keras-nlp)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n",
            "Collecting namex (from keras-core->keras-nlp)\n",
            "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-nlp) (3.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp) (0.15.0)\n",
            "Collecting tensorflow<2.16,>=2.15.0 (from tensorflow-text->keras-nlp)\n",
            "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.59.2)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras-nlp) (3.2.2)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56439 sha256=9e8d5f833733ccd68d0673c53f9514905d85897e628789b5546beca7b1d261a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: namex, tensorflow-estimator, np_utils, keras-preprocessing, keras, gensim, keras-core, tensorboard, tensorflow, tensorflow-text, keras-nlp\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.2\n",
            "    Uninstalling gensim-4.3.2:\n",
            "      Successfully uninstalled gensim-4.3.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.14.0\n",
            "    Uninstalling tensorflow-2.14.0:\n",
            "      Successfully uninstalled tensorflow-2.14.0\n",
            "Successfully installed gensim-4.2.0 keras-2.15.0 keras-core-0.1.7 keras-nlp-0.6.3 keras-preprocessing-1.1.2 namex-0.0.7 np_utils-0.6.0 tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-text-2.15.0\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob 'keras-nlp' 'keras-preprocessing' 'gensim==4.2.0' np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iklSJ4lqUQlT",
        "outputId": "f40d80f4-e6af-4cd2-d2ca-52b85ac812ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Lambda\n",
        "import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from textblob import TextBlob, Word\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import warnings\n",
        "import nltk\n",
        "\n",
        "TRACE = False  # Setting to true is useful when debugging to know which device is being used\n",
        "embedding_dim = 50\n",
        "epochs=100\n",
        "batch_size = 500\n",
        "BATCH = True\n",
        "\n",
        "def set_seeds_and_trace():\n",
        "  os.environ['PYTHONHASHSEED'] = '0'\n",
        "  np.random.seed(42)\n",
        "  tf.random.set_seed(42)\n",
        "  random.seed(42)\n",
        "  if TRACE:\n",
        "    tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "def set_session_with_gpus_and_cores():\n",
        "  cores = multiprocessing.cpu_count()\n",
        "  gpus = len(tf.config.list_physical_devices('GPU'))\n",
        "  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "  sess = tf.compat.v1.Session(config=config)\n",
        "  tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "set_seeds_and_trace()\n",
        "set_session_with_gpus_and_cores()\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('punkt')\n",
        "textblob_tokenizer = lambda x: TextBlob(x).words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l13de14sclyD",
        "outputId": "8c8043d7-c6d3-43e7-d532-233523c4715f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing get_data.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile get_data.sh\n",
        "if [ ! -f yelp.csv ]; then\n",
        "  wget -O yelp.csv https://www.dropbox.com/s/xds4lua69b7okw8/yelp.csv?dl=0\n",
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PvRXU9EMVJMp",
        "outputId": "82a617aa-2c0d-45ed-c527-3d0de7237350",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-21 07:56:34--  https://www.dropbox.com/s/xds4lua69b7okw8/yelp.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6022:18::a27d:4212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/xds4lua69b7okw8/yelp.csv [following]\n",
            "--2023-11-21 07:56:35--  https://www.dropbox.com/s/raw/xds4lua69b7okw8/yelp.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uccde21b6ed74800f623828c604a.dl.dropboxusercontent.com/cd/0/inline/CH-tohTVvxfmGSQ9DvQACiH87pRHx8esMSTz5D3NnapYn01n8ozB8viz0DMFnTv3PNn1PkU1_aA_PsTVOKKFW-dqWS0Ofdf8BlsbsItrvmINYcEb0yRegAJm71q4-U1lYHyUXtEqhhTqA_CjLQU2K9a7/file# [following]\n",
            "--2023-11-21 07:56:35--  https://uccde21b6ed74800f623828c604a.dl.dropboxusercontent.com/cd/0/inline/CH-tohTVvxfmGSQ9DvQACiH87pRHx8esMSTz5D3NnapYn01n8ozB8viz0DMFnTv3PNn1PkU1_aA_PsTVOKKFW-dqWS0Ofdf8BlsbsItrvmINYcEb0yRegAJm71q4-U1lYHyUXtEqhhTqA_CjLQU2K9a7/file\n",
            "Resolving uccde21b6ed74800f623828c604a.dl.dropboxusercontent.com (uccde21b6ed74800f623828c604a.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uccde21b6ed74800f623828c604a.dl.dropboxusercontent.com (uccde21b6ed74800f623828c604a.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8091185 (7.7M) [text/plain]\n",
            "Saving to: ‘yelp.csv’\n",
            "\n",
            "yelp.csv            100%[===================>]   7.72M  47.9MB/s    in 0.2s    \n",
            "\n",
            "2023-11-21 07:56:36 (47.9 MB/s) - ‘yelp.csv’ saved [8091185/8091185]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!bash get_data.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QAWXcLEieD4E"
      },
      "outputs": [],
      "source": [
        "path = './yelp.csv'\n",
        "yelp = pd.read_csv(path)\n",
        "# Create a new DataFrame that only contains the 5-star and 1-star reviews.\n",
        "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
        "X = yelp_best_worst.text\n",
        "y = yelp_best_worst.stars.map({1:0, 5:1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ljgSnKkzeM4-"
      },
      "outputs": [],
      "source": [
        "# Create corpus of sentences such that the sentence has more than 3 words\n",
        "corpus = [line for line in X.values if len(textblob_tokenizer(line))>3]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[:2]"
      ],
      "metadata": {
        "id": "dxrIkyGu409v",
        "outputId": "680dc40d-e56e-4c78-9388-a061f731ce7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!',\n",
              " 'I have no idea why some people give bad reviews about this place. It goes to show you, you can please everyone. They are probably griping about something that their own fault...there are many people like that.\\n\\nIn any case, my friend and I arrived at about 5:50 PM this past Sunday. It was pretty crowded, more than I thought for a Sunday evening and thought we would have to wait forever to get a seat but they said we\\'ll be seated when the girl comes back from seating someone else. We were seated at 5:52 and the waiter came and got our drink orders. Everyone was very pleasant from the host that seated us to the waiter to the server. The prices were very good as well. We placed our orders once we decided what we wanted at 6:02. We shared the baked spaghetti calzone and the small \"Here\\'s The Beef\" pizza so we can both try them. The calzone was huge and we got the smallest one (personal) and got the small 11\" pizza. Both were awesome! My friend liked the pizza better and I liked the calzone better. The calzone does have a sweetish sauce but that\\'s how I like my sauce!\\n\\nWe had to box part of the pizza to take it home and we were out the door by 6:42. So, everything was great and not like these bad reviewers. That goes to show you that  you have to try these things yourself because all these bad reviewers have some serious issues.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-AyyCRQ2-7J",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "At this point we have a list (any iterable will do) of queries that are longer than 3 words. This is normal to filter random queries. Now we must use the `Tokenizer` object to `fit` on the corpus, in order to convert each wor to an ID, and later convert such corpus of list of words into their identifiers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dUlTe1xsgi51",
        "outputId": "7da772be-b36d-4f4c-f9a2-b643cee507ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before the tokenizer: ['My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\\n\\nDo yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I\\'ve ever had.  I\\'m pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\\n\\nWhile EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I\\'ve ever had.\\n\\nAnyway, I can\\'t wait to go back!']\n",
            "After the tokenizer: [[12, 447, 202, 35, 41, 20, 12, 571, 11, 282, 2, 9, 8, 196, 1, 1549, 8, 201, 71, 123, 654, 319, 4500, 43, 2394, 58, 1408, 1478, 50, 483, 8, 196, 2, 50, 28, 572, 664, 20, 1, 3444, 458, 616, 450, 9, 388, 38, 1, 27, 4501, 53, 178, 664, 25, 1, 1631, 15, 46, 41, 1, 138, 85, 600, 4, 1632, 2, 46, 43, 2217, 2726, 9, 8, 1388, 2, 693, 1, 66, 74, 109, 23, 86, 178, 163, 17, 77, 356, 632, 45, 43, 1036, 2, 2395, 80, 130, 54, 15, 113, 9, 9, 8, 99, 170, 140, 20, 1, 122, 545, 196, 3, 23, 1, 475, 2218, 3230, 770, 1409, 2727, 2, 9, 8, 301, 2, 108, 9, 154, 16, 144, 859, 6, 43, 8190, 243, 16, 8, 99, 2, 9, 364, 123, 1, 179, 998, 9, 8, 1, 66, 812, 74, 109, 23, 750, 3, 142, 139, 5, 48, 64]]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "# Use the fit_on_texts method to fit the tokenizer\n",
        "tokenizer.fit_on_texts(corpus) # Fill\n",
        "\n",
        "print(f'Before the tokenizer: {corpus[:1]}')\n",
        "\n",
        "#Now use the same \"trained\" tokenizer to convert the corpus from words to IDs with the texts_to_sequences method\n",
        "tokenized_corpus = tokenizer.texts_to_sequences(corpus)\n",
        "\n",
        "print(f'After the tokenizer: {tokenized_corpus[:1]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "id": "joCqE98U6VSS",
        "outputId": "8bc95293-e7ad-4b00-a018-80298dc16c01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'i': 3,\n",
              " 'a': 4,\n",
              " 'to': 5,\n",
              " 'of': 6,\n",
              " 'is': 7,\n",
              " 'was': 8,\n",
              " 'it': 9,\n",
              " 'in': 10,\n",
              " 'for': 11,\n",
              " 'my': 12,\n",
              " 'that': 13,\n",
              " 'this': 14,\n",
              " 'you': 15,\n",
              " 'with': 16,\n",
              " 'they': 17,\n",
              " 'we': 18,\n",
              " 'have': 19,\n",
              " 'on': 20,\n",
              " 'but': 21,\n",
              " 'are': 22,\n",
              " 'had': 23,\n",
              " 'not': 24,\n",
              " 'so': 25,\n",
              " 'at': 26,\n",
              " 'place': 27,\n",
              " 'food': 28,\n",
              " 'as': 29,\n",
              " 'be': 30,\n",
              " 'great': 31,\n",
              " 'were': 32,\n",
              " 'there': 33,\n",
              " 'good': 34,\n",
              " 'me': 35,\n",
              " 'all': 36,\n",
              " 'if': 37,\n",
              " 'like': 38,\n",
              " 'out': 39,\n",
              " 'just': 40,\n",
              " 'here': 41,\n",
              " 'one': 42,\n",
              " 'their': 43,\n",
              " 'very': 44,\n",
              " 'from': 45,\n",
              " 'get': 46,\n",
              " 'or': 47,\n",
              " 'go': 48,\n",
              " 'time': 49,\n",
              " 'our': 50,\n",
              " \"it's\": 51,\n",
              " 'about': 52,\n",
              " 'up': 53,\n",
              " 'when': 54,\n",
              " 'your': 55,\n",
              " 'been': 56,\n",
              " 'service': 57,\n",
              " 'an': 58,\n",
              " 'can': 59,\n",
              " 'love': 60,\n",
              " 'what': 61,\n",
              " 'some': 62,\n",
              " 'will': 63,\n",
              " 'back': 64,\n",
              " 'really': 65,\n",
              " 'best': 66,\n",
              " 'would': 67,\n",
              " 'by': 68,\n",
              " 'no': 69,\n",
              " 'also': 70,\n",
              " 'which': 71,\n",
              " 'has': 72,\n",
              " 'more': 73,\n",
              " \"i've\": 74,\n",
              " 'always': 75,\n",
              " 'she': 76,\n",
              " 'only': 77,\n",
              " 'he': 78,\n",
              " \"don't\": 79,\n",
              " 'them': 80,\n",
              " 'even': 81,\n",
              " 'well': 82,\n",
              " 'us': 83,\n",
              " 'too': 84,\n",
              " 'do': 85,\n",
              " \"i'm\": 86,\n",
              " 'after': 87,\n",
              " 'because': 88,\n",
              " 'never': 89,\n",
              " 'other': 90,\n",
              " 'first': 91,\n",
              " 'restaurant': 92,\n",
              " 'staff': 93,\n",
              " 'got': 94,\n",
              " 'little': 95,\n",
              " 'nice': 96,\n",
              " 'than': 97,\n",
              " 'make': 98,\n",
              " 'amazing': 99,\n",
              " 'over': 100,\n",
              " 'how': 101,\n",
              " 'know': 102,\n",
              " 'try': 103,\n",
              " 'am': 104,\n",
              " 'who': 105,\n",
              " 'her': 106,\n",
              " 'people': 107,\n",
              " 'delicious': 108,\n",
              " 'ever': 109,\n",
              " 'much': 110,\n",
              " 'could': 111,\n",
              " 'off': 112,\n",
              " 'order': 113,\n",
              " 'then': 114,\n",
              " 'going': 115,\n",
              " 'chicken': 116,\n",
              " 'went': 117,\n",
              " 'friendly': 118,\n",
              " 'did': 119,\n",
              " 'right': 120,\n",
              " 'any': 121,\n",
              " 'menu': 122,\n",
              " 'made': 123,\n",
              " 'say': 124,\n",
              " 'way': 125,\n",
              " 'ordered': 126,\n",
              " 'now': 127,\n",
              " 'experience': 128,\n",
              " 'take': 129,\n",
              " 'fresh': 130,\n",
              " 'new': 131,\n",
              " 'every': 132,\n",
              " 'want': 133,\n",
              " 'day': 134,\n",
              " 'few': 135,\n",
              " 'two': 136,\n",
              " \"didn't\": 137,\n",
              " 'better': 138,\n",
              " 'wait': 139,\n",
              " 'everything': 140,\n",
              " 'bar': 141,\n",
              " \"can't\": 142,\n",
              " 'again': 143,\n",
              " '2': 144,\n",
              " 'eat': 145,\n",
              " 'think': 146,\n",
              " 'night': 147,\n",
              " 'pizza': 148,\n",
              " 'cheese': 149,\n",
              " 'see': 150,\n",
              " 'come': 151,\n",
              " 'favorite': 152,\n",
              " 'down': 153,\n",
              " 'came': 154,\n",
              " 'since': 155,\n",
              " 'phoenix': 156,\n",
              " 'many': 157,\n",
              " 'his': 158,\n",
              " '5': 159,\n",
              " 'before': 160,\n",
              " 'most': 161,\n",
              " 'salad': 162,\n",
              " 'sure': 163,\n",
              " 'happy': 164,\n",
              " 'home': 165,\n",
              " 'find': 166,\n",
              " 'lunch': 167,\n",
              " 'around': 168,\n",
              " 'last': 169,\n",
              " 'while': 170,\n",
              " 'said': 171,\n",
              " 'times': 172,\n",
              " 'still': 173,\n",
              " 'awesome': 174,\n",
              " 'recommend': 175,\n",
              " 'definitely': 176,\n",
              " 'next': 177,\n",
              " 'pretty': 178,\n",
              " 'meal': 179,\n",
              " 'sauce': 180,\n",
              " 'where': 181,\n",
              " 'into': 182,\n",
              " '3': 183,\n",
              " 'years': 184,\n",
              " 'dinner': 185,\n",
              " 'store': 186,\n",
              " 'give': 187,\n",
              " 'another': 188,\n",
              " 'worth': 189,\n",
              " 'something': 190,\n",
              " 'thing': 191,\n",
              " 'minutes': 192,\n",
              " 'table': 193,\n",
              " 'area': 194,\n",
              " 'its': 195,\n",
              " 'excellent': 196,\n",
              " 'bad': 197,\n",
              " 'being': 198,\n",
              " 'feel': 199,\n",
              " 'both': 200,\n",
              " 'perfect': 201,\n",
              " 'took': 202,\n",
              " 'location': 203,\n",
              " 'prices': 204,\n",
              " 'tried': 205,\n",
              " 'big': 206,\n",
              " 'work': 207,\n",
              " 'long': 208,\n",
              " 'found': 209,\n",
              " 'hour': 210,\n",
              " 'side': 211,\n",
              " \"you're\": 212,\n",
              " 'looking': 213,\n",
              " 'wine': 214,\n",
              " 'hot': 215,\n",
              " 'enough': 216,\n",
              " 'these': 217,\n",
              " 'things': 218,\n",
              " 'asked': 219,\n",
              " 'need': 220,\n",
              " 'told': 221,\n",
              " 'lot': 222,\n",
              " '1': 223,\n",
              " 'coffee': 224,\n",
              " 'though': 225,\n",
              " 'should': 226,\n",
              " 'friends': 227,\n",
              " 'free': 228,\n",
              " 'price': 229,\n",
              " 'top': 230,\n",
              " 'atmosphere': 231,\n",
              " 'clean': 232,\n",
              " 'different': 233,\n",
              " 'sandwich': 234,\n",
              " 'anything': 235,\n",
              " 'check': 236,\n",
              " 'sweet': 237,\n",
              " 'each': 238,\n",
              " 'drink': 239,\n",
              " '10': 240,\n",
              " 'bit': 241,\n",
              " 'room': 242,\n",
              " 'bread': 243,\n",
              " 'meat': 244,\n",
              " 'small': 245,\n",
              " 'drinks': 246,\n",
              " 'special': 247,\n",
              " 'town': 248,\n",
              " '4': 249,\n",
              " 'quality': 250,\n",
              " 'fantastic': 251,\n",
              " 'visit': 252,\n",
              " \"that's\": 253,\n",
              " 'once': 254,\n",
              " 'review': 255,\n",
              " 'taste': 256,\n",
              " 'huge': 257,\n",
              " 'cream': 258,\n",
              " 'wonderful': 259,\n",
              " 'far': 260,\n",
              " 'him': 261,\n",
              " 'places': 262,\n",
              " 'actually': 263,\n",
              " 'family': 264,\n",
              " 'house': 265,\n",
              " 'scottsdale': 266,\n",
              " 'super': 267,\n",
              " 'without': 268,\n",
              " 'rice': 269,\n",
              " 'burger': 270,\n",
              " 'look': 271,\n",
              " 'everyone': 272,\n",
              " 'why': 273,\n",
              " 'ask': 274,\n",
              " 'through': 275,\n",
              " 'old': 276,\n",
              " 'oh': 277,\n",
              " 'away': 278,\n",
              " 'same': 279,\n",
              " 'week': 280,\n",
              " 'care': 281,\n",
              " 'breakfast': 282,\n",
              " 'friend': 283,\n",
              " 'customer': 284,\n",
              " 'server': 285,\n",
              " 'those': 286,\n",
              " 'ice': 287,\n",
              " 'loved': 288,\n",
              " 'selection': 289,\n",
              " 'highly': 290,\n",
              " 'fries': 291,\n",
              " 'else': 292,\n",
              " 'such': 293,\n",
              " 'full': 294,\n",
              " 'wanted': 295,\n",
              " 'let': 296,\n",
              " 'beer': 297,\n",
              " \"wasn't\": 298,\n",
              " 'kind': 299,\n",
              " 'sushi': 300,\n",
              " 'tasty': 301,\n",
              " 'business': 302,\n",
              " 'flavor': 303,\n",
              " 'dish': 304,\n",
              " 'probably': 305,\n",
              " 'nothing': 306,\n",
              " 'shop': 307,\n",
              " 'fun': 308,\n",
              " 'enjoy': 309,\n",
              " 'course': 310,\n",
              " 'done': 311,\n",
              " 'items': 312,\n",
              " 'makes': 313,\n",
              " 'eating': 314,\n",
              " 'open': 315,\n",
              " 'water': 316,\n",
              " 'valley': 317,\n",
              " 'local': 318,\n",
              " 'outside': 319,\n",
              " 'thought': 320,\n",
              " 'inside': 321,\n",
              " 'left': 322,\n",
              " 'getting': 323,\n",
              " 'decided': 324,\n",
              " 'does': 325,\n",
              " 'dishes': 326,\n",
              " 'large': 327,\n",
              " 'cool': 328,\n",
              " 'year': 329,\n",
              " 'beef': 330,\n",
              " 'mexican': 331,\n",
              " 'least': 332,\n",
              " 'having': 333,\n",
              " 'fried': 334,\n",
              " 'own': 335,\n",
              " 'must': 336,\n",
              " 'yes': 337,\n",
              " 'chocolate': 338,\n",
              " 'stars': 339,\n",
              " 'three': 340,\n",
              " 'usually': 341,\n",
              " 'hours': 342,\n",
              " 'high': 343,\n",
              " \"i'd\": 344,\n",
              " 'put': 345,\n",
              " 'quite': 346,\n",
              " 'half': 347,\n",
              " 'kids': 348,\n",
              " \"i'll\": 349,\n",
              " 'husband': 350,\n",
              " 'reviews': 351,\n",
              " 'part': 352,\n",
              " 'spot': 353,\n",
              " 'dining': 354,\n",
              " 'during': 355,\n",
              " 'use': 356,\n",
              " 'guy': 357,\n",
              " 'money': 358,\n",
              " 'tacos': 359,\n",
              " 'hard': 360,\n",
              " 'door': 361,\n",
              " 'several': 362,\n",
              " 'call': 363,\n",
              " 'absolutely': 364,\n",
              " 'live': 365,\n",
              " 'yet': 366,\n",
              " 'called': 367,\n",
              " 'drive': 368,\n",
              " 'tell': 369,\n",
              " 'owner': 370,\n",
              " 'someone': 371,\n",
              " '20': 372,\n",
              " 'whole': 373,\n",
              " 'red': 374,\n",
              " 'couple': 375,\n",
              " 'almost': 376,\n",
              " 'used': 377,\n",
              " 'gave': 378,\n",
              " 'disappointed': 379,\n",
              " 'name': 380,\n",
              " 'helpful': 381,\n",
              " 'comes': 382,\n",
              " 'served': 383,\n",
              " \"doesn't\": 384,\n",
              " 'may': 385,\n",
              " 'car': 386,\n",
              " 'plate': 387,\n",
              " 'looked': 388,\n",
              " 'brought': 389,\n",
              " 'green': 390,\n",
              " 'soup': 391,\n",
              " 'stuff': 392,\n",
              " 'stop': 393,\n",
              " 'close': 394,\n",
              " \"won't\": 395,\n",
              " 'fish': 396,\n",
              " 'style': 397,\n",
              " 'dessert': 398,\n",
              " 'spicy': 399,\n",
              " 'pork': 400,\n",
              " 'bring': 401,\n",
              " 'restaurants': 402,\n",
              " 'parking': 403,\n",
              " 'steak': 404,\n",
              " 'music': 405,\n",
              " 'real': 406,\n",
              " 'walked': 407,\n",
              " 'maybe': 408,\n",
              " 'fast': 409,\n",
              " 'dog': 410,\n",
              " 'walk': 411,\n",
              " 'however': 412,\n",
              " \"couldn't\": 413,\n",
              " 'less': 414,\n",
              " 'tasted': 415,\n",
              " 'ago': 416,\n",
              " '6': 417,\n",
              " 'job': 418,\n",
              " 'extra': 419,\n",
              " 'wrong': 420,\n",
              " 'coming': 421,\n",
              " 'cooked': 422,\n",
              " 'until': 423,\n",
              " 'shrimp': 424,\n",
              " 'able': 425,\n",
              " 'often': 426,\n",
              " 'enjoyed': 427,\n",
              " 'end': 428,\n",
              " 'front': 429,\n",
              " 'help': 430,\n",
              " 'person': 431,\n",
              " 'either': 432,\n",
              " 'bacon': 433,\n",
              " 'offer': 434,\n",
              " 'thai': 435,\n",
              " 'beautiful': 436,\n",
              " 'tea': 437,\n",
              " 'needed': 438,\n",
              " 'started': 439,\n",
              " '30': 440,\n",
              " 'manager': 441,\n",
              " 'patio': 442,\n",
              " 'yelp': 443,\n",
              " 'fan': 444,\n",
              " 'especially': 445,\n",
              " 'ok': 446,\n",
              " 'wife': 447,\n",
              " 'waiting': 448,\n",
              " 'felt': 449,\n",
              " 'morning': 450,\n",
              " 'finally': 451,\n",
              " 'flavors': 452,\n",
              " \"isn't\": 453,\n",
              " 'star': 454,\n",
              " 'might': 455,\n",
              " 'trying': 456,\n",
              " 'extremely': 457,\n",
              " 'busy': 458,\n",
              " 'arizona': 459,\n",
              " 'pay': 460,\n",
              " 'today': 461,\n",
              " 'keep': 462,\n",
              " 'myself': 463,\n",
              " 'buy': 464,\n",
              " 'anyone': 465,\n",
              " 'line': 466,\n",
              " '15': 467,\n",
              " 'sit': 468,\n",
              " 'fact': 469,\n",
              " 'start': 470,\n",
              " 'wish': 471,\n",
              " 'trip': 472,\n",
              " 'soon': 473,\n",
              " 'deal': 474,\n",
              " 'white': 475,\n",
              " 'saw': 476,\n",
              " 'tables': 477,\n",
              " 'quick': 478,\n",
              " 'later': 479,\n",
              " 'seen': 480,\n",
              " 'second': 481,\n",
              " 'point': 482,\n",
              " 'waitress': 483,\n",
              " 'chips': 484,\n",
              " \"there's\": 485,\n",
              " 'bowl': 486,\n",
              " 'wow': 487,\n",
              " 'street': 488,\n",
              " 'perfectly': 489,\n",
              " 'warm': 490,\n",
              " 'regular': 491,\n",
              " 'sat': 492,\n",
              " 'plus': 493,\n",
              " 'thanks': 494,\n",
              " 'salsa': 495,\n",
              " 'customers': 496,\n",
              " 'instead': 497,\n",
              " 'yummy': 498,\n",
              " 'cheap': 499,\n",
              " 'kitchen': 500,\n",
              " 'glass': 501,\n",
              " 'az': 502,\n",
              " 'list': 503,\n",
              " 'cake': 504,\n",
              " \"they're\": 505,\n",
              " 'believe': 506,\n",
              " 'lots': 507,\n",
              " 'hands': 508,\n",
              " 'etc': 509,\n",
              " 'chef': 510,\n",
              " 'seriously': 511,\n",
              " 'waiter': 512,\n",
              " 'run': 513,\n",
              " 'decor': 514,\n",
              " '8': 515,\n",
              " 'office': 516,\n",
              " 'life': 517,\n",
              " 'days': 518,\n",
              " 'stay': 519,\n",
              " 'early': 520,\n",
              " 'appetizer': 521,\n",
              " 'beans': 522,\n",
              " 'dr': 523,\n",
              " 'past': 524,\n",
              " 'working': 525,\n",
              " 'although': 526,\n",
              " 'doing': 527,\n",
              " 'comfortable': 528,\n",
              " 'taking': 529,\n",
              " \"haven't\": 530,\n",
              " 'easy': 531,\n",
              " 'already': 532,\n",
              " 'bite': 533,\n",
              " 'truly': 534,\n",
              " 'leave': 535,\n",
              " 'priced': 536,\n",
              " 'overall': 537,\n",
              " 'cut': 538,\n",
              " 'hair': 539,\n",
              " 'pick': 540,\n",
              " 'return': 541,\n",
              " 'four': 542,\n",
              " \"you'll\": 543,\n",
              " 'thank': 544,\n",
              " 'looks': 545,\n",
              " 'totally': 546,\n",
              " 'sandwiches': 547,\n",
              " 'date': 548,\n",
              " 'guys': 549,\n",
              " 'mind': 550,\n",
              " 'please': 551,\n",
              " 'options': 552,\n",
              " 'light': 553,\n",
              " 'read': 554,\n",
              " 'variety': 555,\n",
              " 'serve': 556,\n",
              " 'italian': 557,\n",
              " 'reasonable': 558,\n",
              " 'mouth': 559,\n",
              " '50': 560,\n",
              " 'rolls': 561,\n",
              " 'knew': 562,\n",
              " 'chinese': 563,\n",
              " 'unique': 564,\n",
              " 'anywhere': 565,\n",
              " 'heard': 566,\n",
              " 'choose': 567,\n",
              " 'add': 568,\n",
              " 'gets': 569,\n",
              " 'potato': 570,\n",
              " 'birthday': 571,\n",
              " 'arrived': 572,\n",
              " 'man': 573,\n",
              " 'world': 574,\n",
              " 'horrible': 575,\n",
              " 'type': 576,\n",
              " 'twice': 577,\n",
              " 'seating': 578,\n",
              " 'making': 579,\n",
              " '7': 580,\n",
              " 'employees': 581,\n",
              " 'eaten': 582,\n",
              " 'pasta': 583,\n",
              " 'party': 584,\n",
              " 'counter': 585,\n",
              " 'fine': 586,\n",
              " 'pho': 587,\n",
              " 'pool': 588,\n",
              " 'event': 589,\n",
              " 'hotel': 590,\n",
              " 'burrito': 591,\n",
              " 'bbq': 592,\n",
              " 'waited': 593,\n",
              " 'potatoes': 594,\n",
              " 'park': 595,\n",
              " 'tip': 596,\n",
              " 'group': 597,\n",
              " 'short': 598,\n",
              " 'five': 599,\n",
              " 'yourself': 600,\n",
              " 'head': 601,\n",
              " 'tempe': 602,\n",
              " 'recently': 603,\n",
              " 'others': 604,\n",
              " 'behind': 605,\n",
              " 'roll': 606,\n",
              " 'size': 607,\n",
              " 'mall': 608,\n",
              " 'choice': 609,\n",
              " 'show': 610,\n",
              " 'ate': 611,\n",
              " 'french': 612,\n",
              " 'phone': 613,\n",
              " 'ended': 614,\n",
              " 'cannot': 615,\n",
              " 'saturday': 616,\n",
              " 'under': 617,\n",
              " 'mean': 618,\n",
              " 'weekend': 619,\n",
              " 'seems': 620,\n",
              " '12': 621,\n",
              " 'desert': 622,\n",
              " 'egg': 623,\n",
              " 'along': 624,\n",
              " 'card': 625,\n",
              " 'months': 626,\n",
              " 'impressed': 627,\n",
              " 'fabulous': 628,\n",
              " 'reason': 629,\n",
              " 'between': 630,\n",
              " 'near': 631,\n",
              " 'ingredients': 632,\n",
              " 'sunday': 633,\n",
              " 'seated': 634,\n",
              " 'simple': 635,\n",
              " 'remember': 636,\n",
              " 'charge': 637,\n",
              " 'glad': 638,\n",
              " 'given': 639,\n",
              " 'market': 640,\n",
              " 'stopped': 641,\n",
              " 'girl': 642,\n",
              " 'worst': 643,\n",
              " 'bill': 644,\n",
              " 'main': 645,\n",
              " 'spend': 646,\n",
              " \"wouldn't\": 647,\n",
              " 'ordering': 648,\n",
              " 'cute': 649,\n",
              " 'taco': 650,\n",
              " 'across': 651,\n",
              " 'portions': 652,\n",
              " 'authentic': 653,\n",
              " 'sitting': 654,\n",
              " 'surprised': 655,\n",
              " 'gone': 656,\n",
              " 'guess': 657,\n",
              " 'expect': 658,\n",
              " 'hand': 659,\n",
              " 'kept': 660,\n",
              " 'hit': 661,\n",
              " 'ready': 662,\n",
              " 'completely': 663,\n",
              " 'quickly': 664,\n",
              " 'problem': 665,\n",
              " 'entire': 666,\n",
              " 'grilled': 667,\n",
              " 'offered': 668,\n",
              " 'butter': 669,\n",
              " 'weeks': 670,\n",
              " 'moved': 671,\n",
              " 'liked': 672,\n",
              " 'garlic': 673,\n",
              " 'hope': 674,\n",
              " 'sometimes': 675,\n",
              " 'low': 676,\n",
              " 'cold': 677,\n",
              " 'black': 678,\n",
              " 'shopping': 679,\n",
              " 'daughter': 680,\n",
              " 'amount': 681,\n",
              " 'attentive': 682,\n",
              " 'received': 683,\n",
              " 'takes': 684,\n",
              " 'tomato': 685,\n",
              " 'needs': 686,\n",
              " 'oil': 687,\n",
              " 'professional': 688,\n",
              " 'talk': 689,\n",
              " 'cost': 690,\n",
              " 'face': 691,\n",
              " 'donuts': 692,\n",
              " 'simply': 693,\n",
              " 'opened': 694,\n",
              " 'burgers': 695,\n",
              " 'recommended': 696,\n",
              " 'exactly': 697,\n",
              " 'sorry': 698,\n",
              " '9': 699,\n",
              " 'packed': 700,\n",
              " 'plenty': 701,\n",
              " 'set': 702,\n",
              " 'tastes': 703,\n",
              " 'downtown': 704,\n",
              " 'cafe': 705,\n",
              " 'school': 706,\n",
              " 'wall': 707,\n",
              " 'spent': 708,\n",
              " 'including': 709,\n",
              " 'taken': 710,\n",
              " 'seem': 711,\n",
              " 'literally': 712,\n",
              " 'homemade': 713,\n",
              " '00': 714,\n",
              " 'evening': 715,\n",
              " 'feeling': 716,\n",
              " 'bottle': 717,\n",
              " 'walking': 718,\n",
              " 'single': 719,\n",
              " 'asian': 720,\n",
              " 'watch': 721,\n",
              " 'ambiance': 722,\n",
              " 'die': 723,\n",
              " 'rude': 724,\n",
              " 'lettuce': 725,\n",
              " 'late': 726,\n",
              " 'owners': 727,\n",
              " 'game': 728,\n",
              " 'stores': 729,\n",
              " 'idea': 730,\n",
              " 'goes': 731,\n",
              " 'treat': 732,\n",
              " 'sign': 733,\n",
              " 'healthy': 734,\n",
              " '25': 735,\n",
              " 'friday': 736,\n",
              " 'neighborhood': 737,\n",
              " 'chain': 738,\n",
              " 'club': 739,\n",
              " 'dogs': 740,\n",
              " 'okay': 741,\n",
              " 'itself': 742,\n",
              " 'filled': 743,\n",
              " 'city': 744,\n",
              " 'salads': 745,\n",
              " 'crust': 746,\n",
              " 'dry': 747,\n",
              " 'pita': 748,\n",
              " 'decent': 749,\n",
              " 'anyway': 750,\n",
              " 'play': 751,\n",
              " 'prepared': 752,\n",
              " 'says': 753,\n",
              " 'ones': 754,\n",
              " 'month': 755,\n",
              " 'bought': 756,\n",
              " 'chance': 757,\n",
              " 'available': 758,\n",
              " 'rest': 759,\n",
              " 'blue': 760,\n",
              " 'roasted': 761,\n",
              " 'beat': 762,\n",
              " 'forget': 763,\n",
              " 'change': 764,\n",
              " 'specials': 765,\n",
              " 'yum': 766,\n",
              " 'share': 767,\n",
              " 'note': 768,\n",
              " 'beers': 769,\n",
              " 'eggs': 770,\n",
              " 'saying': 771,\n",
              " 'piece': 772,\n",
              " 'soft': 773,\n",
              " 'understand': 774,\n",
              " 'servers': 775,\n",
              " 'mention': 776,\n",
              " 'company': 777,\n",
              " 'w': 778,\n",
              " 'corn': 779,\n",
              " 'heaven': 780,\n",
              " \"we've\": 781,\n",
              " 'spa': 782,\n",
              " 'added': 783,\n",
              " 'onion': 784,\n",
              " 'matter': 785,\n",
              " 'within': 786,\n",
              " 'based': 787,\n",
              " 'honestly': 788,\n",
              " 'forward': 789,\n",
              " 'portion': 790,\n",
              " 'la': 791,\n",
              " 'attention': 792,\n",
              " 'lady': 793,\n",
              " 'bartender': 794,\n",
              " 'center': 795,\n",
              " 'spring': 796,\n",
              " 'tender': 797,\n",
              " 'expensive': 798,\n",
              " 'located': 799,\n",
              " 'meals': 800,\n",
              " 'art': 801,\n",
              " 'wings': 802,\n",
              " 'flavorful': 803,\n",
              " 'onions': 804,\n",
              " 'greeted': 805,\n",
              " 'rather': 806,\n",
              " 'mom': 807,\n",
              " 'immediately': 808,\n",
              " 'total': 809,\n",
              " 'finish': 810,\n",
              " 'seemed': 811,\n",
              " 'toast': 812,\n",
              " 'miss': 813,\n",
              " 'appetizers': 814,\n",
              " 'number': 815,\n",
              " 'mine': 816,\n",
              " 'movie': 817,\n",
              " \"you've\": 818,\n",
              " 'choices': 819,\n",
              " 'true': 820,\n",
              " 'sausage': 821,\n",
              " 'excited': 822,\n",
              " 'lived': 823,\n",
              " 'upon': 824,\n",
              " 'plates': 825,\n",
              " 'pleasant': 826,\n",
              " 'longer': 827,\n",
              " 'favorites': 828,\n",
              " 'crispy': 829,\n",
              " 'giving': 830,\n",
              " 'east': 831,\n",
              " 'salmon': 832,\n",
              " 'yeah': 833,\n",
              " 'foods': 834,\n",
              " 'closed': 835,\n",
              " 'easily': 836,\n",
              " 'toppings': 837,\n",
              " 'item': 838,\n",
              " 'cup': 839,\n",
              " '11': 840,\n",
              " 'finished': 841,\n",
              " 'talking': 842,\n",
              " 'summer': 843,\n",
              " 'minute': 844,\n",
              " '100': 845,\n",
              " 'pie': 846,\n",
              " \"aren't\": 847,\n",
              " 'thinking': 848,\n",
              " 'incredible': 849,\n",
              " 'gym': 850,\n",
              " 'outstanding': 851,\n",
              " 'visiting': 852,\n",
              " 'level': 853,\n",
              " 'questions': 854,\n",
              " 'strip': 855,\n",
              " 'stuffed': 856,\n",
              " 'vegetarian': 857,\n",
              " 'non': 858,\n",
              " 'pieces': 859,\n",
              " 'box': 860,\n",
              " 'space': 861,\n",
              " 'grill': 862,\n",
              " 'together': 863,\n",
              " 'moment': 864,\n",
              " 'crab': 865,\n",
              " 'joint': 866,\n",
              " 'whatever': 867,\n",
              " 'worked': 868,\n",
              " 'noodles': 869,\n",
              " 'plan': 870,\n",
              " 'fat': 871,\n",
              " 'lovely': 872,\n",
              " 'sort': 873,\n",
              " 'sides': 874,\n",
              " 'hungry': 875,\n",
              " 'ribs': 876,\n",
              " 'book': 877,\n",
              " 'entree': 878,\n",
              " 'dip': 879,\n",
              " 'noticed': 880,\n",
              " 'crazy': 881,\n",
              " 'works': 882,\n",
              " '99': 883,\n",
              " 'baked': 884,\n",
              " 'personal': 885,\n",
              " 'baby': 886,\n",
              " 'orange': 887,\n",
              " '40': 888,\n",
              " 'girls': 889,\n",
              " 'mixed': 890,\n",
              " 'bag': 891,\n",
              " 'hate': 892,\n",
              " 'poor': 893,\n",
              " 'lemon': 894,\n",
              " 'dirty': 895,\n",
              " 'hummus': 896,\n",
              " 'crowded': 897,\n",
              " 'orders': 898,\n",
              " 'tasting': 899,\n",
              " 'nails': 900,\n",
              " 'average': 901,\n",
              " 'curry': 902,\n",
              " 'products': 903,\n",
              " 'mac': 904,\n",
              " 'using': 905,\n",
              " 'massage': 906,\n",
              " 'split': 907,\n",
              " 'picked': 908,\n",
              " 'milk': 909,\n",
              " 'grab': 910,\n",
              " 'pass': 911,\n",
              " 'value': 912,\n",
              " 'turkey': 913,\n",
              " 'heat': 914,\n",
              " 'seat': 915,\n",
              " 'fruit': 916,\n",
              " 'helped': 917,\n",
              " 'bucks': 918,\n",
              " 'turned': 919,\n",
              " 'tiny': 920,\n",
              " 'dark': 921,\n",
              " 'slow': 922,\n",
              " 'vegan': 923,\n",
              " 'outdoor': 924,\n",
              " 'young': 925,\n",
              " 'com': 926,\n",
              " 'grocery': 927,\n",
              " 'case': 928,\n",
              " 'perfection': 929,\n",
              " 'reading': 930,\n",
              " 'classes': 931,\n",
              " 'paying': 932,\n",
              " 'afternoon': 933,\n",
              " 'stand': 934,\n",
              " 'corner': 935,\n",
              " 'awful': 936,\n",
              " 'mix': 937,\n",
              " 'sauces': 938,\n",
              " 'somewhere': 939,\n",
              " 'tomatoes': 940,\n",
              " 'except': 941,\n",
              " 'empty': 942,\n",
              " 'fair': 943,\n",
              " 'combo': 944,\n",
              " 'per': 945,\n",
              " 'paid': 946,\n",
              " 'bean': 947,\n",
              " 'crowd': 948,\n",
              " 'fix': 949,\n",
              " 'cook': 950,\n",
              " 'entrees': 951,\n",
              " 'appointment': 952,\n",
              " 'damn': 953,\n",
              " 'class': 954,\n",
              " 'dressing': 955,\n",
              " 'tons': 956,\n",
              " 'notch': 957,\n",
              " 'knowledgeable': 958,\n",
              " 'loves': 959,\n",
              " 'view': 960,\n",
              " 'touch': 961,\n",
              " 'lucky': 962,\n",
              " 'hell': 963,\n",
              " 'vanilla': 964,\n",
              " 'stayed': 965,\n",
              " 'word': 966,\n",
              " 'watching': 967,\n",
              " 'cookie': 968,\n",
              " 'training': 969,\n",
              " 'soda': 970,\n",
              " 'serving': 971,\n",
              " 'veggie': 972,\n",
              " 'alone': 973,\n",
              " 'bunch': 974,\n",
              " 'combination': 975,\n",
              " 'met': 976,\n",
              " 'mushrooms': 977,\n",
              " 'cash': 978,\n",
              " 'above': 979,\n",
              " 'locations': 980,\n",
              " 'p': 981,\n",
              " 'carne': 982,\n",
              " 'knows': 983,\n",
              " 'olive': 984,\n",
              " 'product': 985,\n",
              " 'interesting': 986,\n",
              " 'section': 987,\n",
              " 'boyfriend': 988,\n",
              " 'lamb': 989,\n",
              " 'frozen': 990,\n",
              " 'reasonably': 991,\n",
              " 'shoes': 992,\n",
              " 'theater': 993,\n",
              " 'yogurt': 994,\n",
              " 'honest': 995,\n",
              " 'chili': 996,\n",
              " 'bun': 997,\n",
              " 'complete': 998,\n",
              " 'speak': 999,\n",
              " 'basil': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ucoEJtOa2-7K",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "nb_samples = sum(len(s) for s in tokenized_corpus)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bfR6qIZZhIHd",
        "outputId": "30cac715-c79a-4bb7-b4f4-f6e4c4cf792d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 corpus items are [[12, 447, 202, 35, 41, 20, 12, 571, 11, 282, 2, 9, 8, 196, 1, 1549, 8, 201, 71, 123, 654, 319, 4500, 43, 2394, 58, 1408, 1478, 50, 483, 8, 196, 2, 50, 28, 572, 664, 20, 1, 3444, 458, 616, 450, 9, 388, 38, 1, 27, 4501, 53, 178, 664, 25, 1, 1631, 15, 46, 41, 1, 138, 85, 600, 4, 1632, 2, 46, 43, 2217, 2726, 9, 8, 1388, 2, 693, 1, 66, 74, 109, 23, 86, 178, 163, 17, 77, 356, 632, 45, 43, 1036, 2, 2395, 80, 130, 54, 15, 113, 9, 9, 8, 99, 170, 140, 20, 1, 122, 545, 196, 3, 23, 1, 475, 2218, 3230, 770, 1409, 2727, 2, 9, 8, 301, 2, 108, 9, 154, 16, 144, 859, 6, 43, 8190, 243, 16, 8, 99, 2, 9, 364, 123, 1, 179, 998, 9, 8, 1, 66, 812, 74, 109, 23, 750, 3, 142, 139, 5, 48, 64], [3, 19, 69, 730, 273, 62, 107, 187, 197, 351, 52, 14, 27, 9, 731, 5, 610, 15, 15, 59, 551, 272, 17, 22, 305, 8191, 52, 190, 13, 43, 335, 1821, 33, 22, 157, 107, 38, 13, 10, 121, 928, 12, 283, 2, 3, 572, 26, 52, 159, 560, 1367, 14, 524, 633, 9, 8, 178, 897, 73, 97, 3, 320, 11, 4, 633, 715, 2, 320, 18, 67, 19, 5, 139, 1317, 5, 46, 4, 915, 21, 17, 171, 1550, 30, 634, 54, 1, 642, 382, 64, 45, 578, 371, 292, 18, 32, 634, 26, 159, 5688, 2, 1, 512, 154, 2, 94, 50, 239, 898, 272, 8, 44, 826, 45, 1, 1440, 13, 634, 83, 5, 1, 512, 5, 1, 285, 1, 204, 32, 44, 34, 29, 82, 18, 1593, 50, 898, 254, 18, 324, 61, 18, 295, 26, 417, 8192, 18, 1018, 1, 884, 2872, 2873, 2, 1, 245, 1410, 1, 330, 148, 25, 18, 59, 200, 103, 80, 1, 2873, 8, 257, 2, 18, 94, 1, 5044, 42, 885, 2, 94, 1, 245, 840, 148, 200, 32, 174, 12, 283, 672, 1, 148, 138, 2, 3, 672, 1, 2873, 138, 1, 2873, 325, 19, 4, 8193, 180, 21, 253, 101, 3, 38, 12, 180, 18, 23, 5, 860, 352, 6, 1, 148, 5, 129, 9, 165, 2, 18, 32, 39, 1, 361, 68, 417, 5689, 25, 140, 8, 31, 2, 24, 38, 217, 197, 1979, 13, 731, 5, 610, 15, 13, 15, 19, 5, 103, 217, 218, 600, 88, 36, 217, 197, 1979, 19, 62, 1504, 1368], [11066, 11067, 2, 3, 60, 11068, 410, 595, 51, 44, 1677, 2, 5045, 68, 4, 222, 6, 4502, 4, 622, 11069, 2396, 3024, 11070, 2, 4, 2054, 16, 4503, 1, 266, 595, 2, 8194, 4085, 325, 4, 259, 418, 6, 2219, 1, 595, 232, 2, 6697, 15, 59, 166, 2220, 4504, 2, 11071, 540, 53, 11072, 799, 36, 100, 1, 595, 2, 4502, 1, 5690, 10, 194, 7, 257, 5, 296, 1, 740, 513, 751, 2, 11073], [1551, 441, 2494, 11074, 7, 4, 34, 623, 24, 5, 48, 182, 1713, 21, 296, 35, 4086, 15, 37, 15, 19, 121, 1368, 6698, 1099, 999, 16, 2494, 2, 732, 1, 357, 16, 62, 2601, 29, 15, 1287, 55, 928, 2, 344, 30, 655, 37, 15, 79, 411, 39, 546, 1633, 29, 3, 40, 119, 38, 3, 75, 124, 5691, 22, 8195, 51, 101, 18, 6699, 45, 80, 13, 7, 1182, 494, 5, 2494, 2, 158, 174, 93, 818, 94, 4, 284, 11, 517], [1479, 61, 212, 527, 2, 368, 41, 87, 3, 611, 41, 3, 23, 5, 48, 64, 1, 177, 134, 11, 73, 1, 28, 7, 13, 34, 14, 649, 95, 390, 1183, 385, 19, 656, 11075, 11076, 37, 3, 1714, 56, 1079, 153, 4505, 3231, 5, 1164, 3025, 170, 448, 5, 1080, 1764, 6700, 488, 1, 1871, 1411, 733, 1765, 12, 1146, 2, 12, 95, 4506, 2728, 11077, 11, 2602, 4, 131, 27, 5, 103, 9, 388, 11078, 45, 1, 319, 21, 54, 3, 694, 1, 361, 3, 8, 345, 26, 531, 68, 1, 514, 1081, 2, 3026, 321, 3, 126, 185, 11, 136, 5, 48, 1, 122, 8, 174, 3, 288, 1120, 36, 1, 555, 4507, 1262, 3729, 1822, 1822, 977, 190, 1412, 10, 1019, 1594, 9, 123, 9, 1288, 5, 567, 190, 1410, 61, 74, 23, 25, 260, 791, 5046, 424, 4508, 2, 4509, 5047, 5692, 11079, 650, 17, 22, 200, 32, 44, 108, 800, 21, 1, 424, 4508, 5048, 1, 610, 25, 110, 303, 3, 5693, 62, 1823, 45, 12, 11080, 3729, 2, 1822, 1822, 5049, 2603, 293, 4, 1766, 1, 495, 141, 7, 2604, 3, 65, 2605, 53, 3, 8, 822, 5, 103, 1, 1480, 495, 21, 9, 8, 84, 215, 10, 469, 9, 36, 8, 21, 86, 4, 206, 6701, 54, 9, 382, 5, 215, 1262, 1, 2495, 7, 5694, 2, 108, 17, 1505, 3445, 2, 62, 916, 10, 33, 84, 71, 7, 4, 498, 1263, 29, 37, 1, 34, 28, 298, 216, 5, 2055, 35, 100, 1, 801, 10, 14, 92, 11081, 119, 86, 4, 3232, 11, 331, 5050, 801, 2, 8196, 8197, 7, 12, 6702, 485, 4, 4087, 6, 106, 2, 2874, 1481, 100, 1, 495, 141, 51, 99, 36, 1, 4088, 22, 31, 60, 1, 2729]]\n",
            "Length of corpus is 4056\n"
          ]
        }
      ],
      "source": [
        "print(f'First 5 corpus items are {tokenized_corpus[:5]}')\n",
        "print(f'Length of corpus is {len(tokenized_corpus)}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2B_z5Udki-_s",
        "outputId": "1a06abb6-a5cd-45a7-d63d-7c0ca80968ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "type(tokenized_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B_Z1eJZrhK7K"
      },
      "outputs": [],
      "source": [
        "# This is the algorithmic part of batching the dataset and yielding the window of words and expected middle word for each bacth as a generator.\n",
        "def generate_data(corpus, vocab_size, window_size=2, sentence_batch_size=15,  batch_size=250):\n",
        "    np.random.shuffle(np.array(corpus))\n",
        "    number_of_sentence_batches = (len(corpus) // sentence_batch_size) + 1\n",
        "    for batch in range(number_of_sentence_batches):\n",
        "        lower_end = batch*batch_size\n",
        "        upper_end = (batch+1)*batch_size if batch+1 < number_of_sentence_batches else len(corpus)\n",
        "        mini_batch_size = upper_end - lower_end\n",
        "        maxlen = window_size*2\n",
        "        X = []\n",
        "        Y = []\n",
        "        for review_id, words in enumerate(corpus[lower_end:upper_end]):\n",
        "            L = len(words)\n",
        "            for index, word in enumerate(words):\n",
        "                contexts = []\n",
        "                labels   = []\n",
        "                s = index - window_size\n",
        "                e = index + window_size + 1\n",
        "\n",
        "                contexts.append([words[i] for i in range(s, e) if 0 <= i < L and i != index])\n",
        "                labels.append(word)\n",
        "\n",
        "                x = pad_sequences(contexts, maxlen=maxlen)\n",
        "                y = to_categorical(labels, vocab_size)\n",
        "                X.append(x)\n",
        "                Y.append(y)\n",
        "        X = tf.constant(X)\n",
        "        Y = tf.constant(Y)\n",
        "        number_of_batches = len(X) // batch_size\n",
        "        for real_batch in range(number_of_batches):\n",
        "          lower_end = batch*batch_size\n",
        "          upper_end = (batch+1)*batch_size\n",
        "          batch_X = tf.squeeze(X[lower_end:upper_end])\n",
        "          batch_Y = tf.squeeze(Y[lower_end:upper_end])\n",
        "          yield (batch_X, batch_Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "nfsYbRRS2-7N",
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Notice now in a sample how we construct X and y to predict words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OvOclN8T2-7N",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "iterable = generate_data(corpus=tokenized_corpus, vocab_size=vocab_size, batch_size=10)\n",
        "sample_x, sample_y = next(iterable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ak0gTIQs2-7O",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "a1419588-2f4f-4844-f783-a1401c1540fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 4), dtype=int32, numpy=\n",
              "array([[  0,   0, 447, 202],\n",
              "       [  0,  12, 202,  35],\n",
              "       [ 12, 447,  35,  41],\n",
              "       [447, 202,  41,  20],\n",
              "       [202,  35,  20,  12],\n",
              "       [ 35,  41,  12, 571],\n",
              "       [ 41,  20, 571,  11],\n",
              "       [ 20,  12,  11, 282],\n",
              "       [ 12, 571, 282,   2],\n",
              "       [571,  11,   2,   9]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "sample_y_numpy = sample_y.numpy()\n",
        "\n",
        "sample_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ix8s4Knh2-7O",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "cc3502b0-0cef-43f9-ae4f-cb6c217c6747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              " array([ 12, 447, 202,  35,  41,  20,  12, 571,  11, 282]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\n",
        "np.where(sample_y_numpy == 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpvnqGOI2-7O",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Now comes the core part, defining the model. Keras provides a convenient Sequential model class to just `add` layers of any type and they will just work. Let's add an `Embedding` layer (that will map the word ids into a vector of size 100), a `Lambda` to average the words out in a sentence, and a `Dense layer` to select the best word on the other end. This is classic CBOW.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHtu75Kpi6XF"
      },
      "outputs": [],
      "source": [
        "cbow = Sequential()\n",
        "cbow.add()  # Add an Embedding layer with input_dim vocab_size, output_dim to be embedding_dim, and the input_length to be twice our window\n",
        "cbow.add()  # Add a Lambda that takes a lambda function using the K.mean method to average the words. The output_shape should be (dim, ).\n",
        "cbow.add()  # Add a classic Dense layer to just select with a softmax the best word\n",
        "# Compile the model with a loss and optimizer of your liking.\n",
        "cbow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y0Truv1f7x9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt2xo_G02-7O",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "cbow.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g44ICdUcj7ZL"
      },
      "outputs": [],
      "source": [
        "def fit_model():\n",
        "    if not BATCH:\n",
        "        # If we are not batching, Fill how to get X AND Y\n",
        "        X, Y = None # Fill\n",
        "        print(f'Size of X is {X.shape} and Y is {Y.shape}')\n",
        "        cbow.fit(X, Y, epochs = epochs)\n",
        "    else:\n",
        "        # Implement the batching logic to train the model (Hint: use the train_on_batch method of Keras models)\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTM2wqbzke5n"
      },
      "outputs": [],
      "source": [
        "fit_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR97HVOqkoMI"
      },
      "outputs": [],
      "source": [
        "with open('./cbow_scratch_synonims.txt' ,'w') as f:\n",
        "    f.write('{} {}\\n'.format(vocab_size-1, embedding_dim))\n",
        "    vectors = cbow.get_weights()[0]\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        str_vec = ' '.join(map(str, list(vectors[i, :])))\n",
        "        f.write('{} {}\\n'.format(word, str_vec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvMp9eWsk2Z-"
      },
      "outputs": [],
      "source": [
        "w2v = gensim.models.KeyedVectors.load_word2vec_format('./cbow_scratch_synonims.txt', binary=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0dw_S7Kk6lW"
      },
      "outputs": [],
      "source": [
        "w2v.most_similar(positive=['gasoline'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCmSyCj8k6He"
      },
      "outputs": [],
      "source": [
        "w2v.most_similar(negative=['apple'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjvrCdY5lkJk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}